# 🤖 KHUDA AI 데이터 분석 동아리 저장소

> 이 저장소는 경희대학교 AI 데이터 분석 동아리 **KHUDA**의 스터디 및 실습 기록을 정리한 공간입니다.  
> 데이터 분석 이론 학습, 실습 자료, 프로젝트 결과물 등을 구조화하여 저장합니다.

---

## 📌 저장소 목적

- KHUDA의 내부 학습자료, 요약문서, 실습 코드 등을 **버전 관리** 및 **공유**함
- 발제 정리는 주로 `.md`로 업로드

---

## 📂 현재 KHUDA 발제 정리 업로드 자료

| 날짜 | 제목 | 형식 | 설명 |
|------|------|------|------|
| 2025-07-28 | [[3장 분류]](<KHUDA 발제 정리/3장 분류/3장 분류 내용정리.md>) | `.md` | 머신러닝 분류 알고리즘 이론 정리 |
| 2025-07-28 | [[4장 모델 훈련]](<KHUDA 발제 정리/4장 모델 훈련/4장 모델 훈련 내용정리.md>)| `.md` | 머신러닝 모델 훈련 이론 정리 |
| 2025-08-05 | [[5장 서포트 벡터 머신]](<KHUDA 발제 정리/5장 서포트 벡터 머신/5장 내용정리.md>) | `.md` | 머신러닝 서포트 벡터 머신 이론 정리 |
| 2025-08-05 | [[6장 결정 트리]](<KHUDA 발제 정리/6장 결정 트리/6장 내용 정리.md>) | `.md` | 결정 트리 알고리즘 이론 정리 |
| 2025-08-09 | [[7장 앙상블 학습과 랜덤 포레스트]](<KHUDA 발제 정리/7장 앙상블 학습과 랜덤 포레스트/7장 내용 정리.md>) | `.md` | 앙상블 학습, 랜덤 포레스트 알고리즘 이론 정리 |
| 2025-08-17 | [[8장 차원 축소]](<KHUDA 발제 정리/8장 차원 축소/8장 내용정리.md>) | `.md` | 차원 축소 알고리즘 이론 정리 |
| 2025-08-18 | [[9장 비지도 학습]](<KHUDA 발제 정리/9장 비지도 학습/9장 내용정리.md>) | `.md` | 비지도 학습 알고리즘 이론 정리 |

---

## 🧾 KHUDA 발제 정리 내용 미리보기

> 📄 **3장 분류**  
> - 3.1 MNIST
> - 3.2 이진 분류기 훈련
> - 3.3 성능 측정
> - 3.4 다중 분류
> - 3.5 오류 분석
> - 3.6 다중 레이블 분류
> - 3.7 다중 출력 분류 

> 📄 **4장 모델 훈련**  
> - 4.1 선형 회귀
> - 4.2 경사 하강법
> - 4.3 다항 회귀
> - 4.4 학습 곡선
> - 4.5 규제가 있는 선형 모델
> - 4.6 로지스틱 회귀

> 📄 **5장 서포트 벡터 머신**  
> - 5.1 선형 SVM 분류
> - 5.2 비선형 SVM 분류
> - 5.3 SVM 회귀
> - 5.4 SVM 이론
> - 5.5 쌍대 문제

> 📄 **6장 결정 트리**  
> - 6.1 결정 트리의 학습과 시각화
> - 6.2 예측
> - 6.3 클래스 확률 추정
> - 6.4 CART 훈련 알고리즘
> - 6.5 지니 불순도 또는 엔트로피?
> - 6.7 규제 매개변수
> - 6.8 회귀
> - 6.9 축 방향에 대한 민감성
> - 6.10 결정 트리의 분산 문제

> 📄 **7장 앙상블 학습과 랜덤 포레스트**  
> - 7.1 투표 기반 분류기
> - 7.2 배깅과 페이스팅
> - 7.3 랜덤 패치와 랜덤 서브스페이스
> - 7.4 랜덤 포레스트
> - 7.5 부스팅
> - 7.6 스태킹

> 📄 **8장 차원 축소**  
> - 8.1 차원의 저주
> - 8.2 차원 축소를 위한 접근법
> - 8.3 주성분 분석
> - 8.4 랜덤 투영
> - 8.5 지역 선형 임베딩
> - 8.6 다른 차원 축소 기법

> 📄 **9장 비지도 학습**  
> - 9.1 군집
> - 9.2 가우스 혼합
---

## 🧠 참고 교재 및 링크

- 오렐이앙 제롱-핸즈온 머신러닝(3판)

---

## 🤖토이프로젝트

### 📈 서울시 전세사기 위험도 예측을 위한 데이터 전처리

### 1. 프로젝트 개요
본 프로젝트는 서울시 **오피스텔** 및 **연립다세대**의 전월세 실거래가 데이터를 기반으로, 잠재적 위험 신호를 감지하는 예측 모델을 구축하기 위한 데이터 전처리 과정을 다룹니다. 원천 데이터를 수집, 통합, 정제하고 모델 학습에 필요한 피쳐를 생성하는 것을 목표로 합니다.

### 2. 데이터 소스 📂
- **내부 데이터**
    - `오피스텔(전월세)_실거래가` (2022-2024년)
    - `연립다세대(전월세)_실거래가` (2022-2024년)
    - `공시가격` 데이터 (매매가 추정을 위해 사용)
- **외부 데이터**
    - `한국은행 기준금리` (월별)
    - `KB 매수우위지수` (서울 전체, 월별)

### 3. 전처리 및 피쳐 엔지니어링 과정 🛠️

#### 3.1. 데이터 통합 및 기본 정제
1.  **주택 유형별 데이터 통합:** `오피스텔`과 `연립다세대`의 3개년치 전월세 데이터를 각각 통합한 후, `주택유형` 열('오피스텔', '연립다세대')을 추가하여 하나의 전월세 데이터(`rent.csv`)로 병합했습니다.
2.  **추정 매매가 데이터 생성:** 개별 `매매 실거래가` 데이터 확보의 한계로, **`공시가격`에 특정 현실화율을 적용하여 '추정 매매가'를 산정**하여 사용했습니다.
3.  **최종 병합:** `rent.csv`를 기준으로, `도로명주소`가 일치하는 '추정 매매가'를 Left Merge 방식으로 병합하여 `data_final.csv`를 생성했습니다.

#### 3.2. 피쳐 생성 및 변환
1.  **`건축연한` 생성:** `계약년월`과 `건축년도`를 이용해 건물의 나이를 나타내는 `건축연한` 피쳐를 생성했습니다.
2.  **주소 정제:** `시군구`와 `도로명` 열을 조합하여 상세 주소 정보를 생성하고, 불필요한 주소 관련 열들을 제거했습니다.
3.  **단위 변환:** `보증금(만원)` 열에 10,000을 곱하여 원 단위의 `보증금` 열을 생성했습니다.
4.  **`계약날짜` 생성:** `계약년월`과 `계약일`을 조합하여 분석에 용이한 `datetime` 형식의 `계약날짜` 열을 생성했습니다.
5.  **외부 지표 추가:**
    - **`기준금리`**: `계약날짜`를 기준으로, `pd.merge_asof`를 사용하여 각 계약 시점의 기준금리를 정확하게 매칭했습니다.
    - **`매수우위지수`**: Wide 형태의 원본 데이터를 Melt하여 Long 형태로 변환 후, `계약년월`을 기준으로 병합했습니다.
6.  **`전세가율` 계산:** 최종적으로 `보증금 / 추정매매가` 공식을 통해 핵심 파생 변수인 **`전세가율`**을 생성했습니다. ❗**주의:** 이 `전세가율`은 **실거래가가 아닌 공시가격 기반의 추정치**로 계산되었으므로, 실제 시장 상황과 차이가 있을 수 있습니다.

#### 3.3. 최종 정제 (모델링 준비)
1.  **결측치 및 이상치 제거:** `전세가율`이 계산되지 않았거나(NaN), 비정상적인 범위(10% 미만, 150% 초과)에 있는 데이터를 제거했습니다.
2.  **카테고리 피쳐 변환:** `주택유형` 열을 `pd.get_dummies`를 이용해 **원-핫 인코딩**하여 숫자형 데이터로 변환했습니다.
3.  **불필요한 피쳐 제거:** 피쳐 엔지니어링 과정에서 사용된 원본 열들(`계약년월`, `계약일` 등)을 최종적으로 삭제하여 데이터셋을 완성했습니다.

### 4. 최종 데이터셋 🚀
- **파일명:** `preprocessed_final.csv`
- **주요 피쳐:** `NO`, `전세가율`, `건축연한`, `계약날짜`, `보증금`, `추정매매가`, `기준금리`, `매수우위지수`, `주택유형_오피스텔`, `주택유형_연립다세대` 등

### 5. 모델링팀에 전달
  
- 완성된 `preprocessed_final.csv`은 모델링팀으로 전달되었습니다.

### 6. 전처리 코드

- [preprocessing.ipynb](toy_proj/preprocessing.ipynb)